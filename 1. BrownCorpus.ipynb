{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32144b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b5d576",
   "metadata": {},
   "source": [
    "**<u>Explore Brown Corpus and find the size, tokens, categories</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca432da",
   "metadata": {},
   "source": [
    "**Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c89c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGOGIRES of Brown Corpus : \n",
      "  ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "\n",
      " No. of CATEGORIES in the Brown Corpus :  15\n"
     ]
    }
   ],
   "source": [
    "print(\"CATEGOGIRES of Brown Corpus : \\n \", brown.categories())\n",
    "print(\"\\n No. of CATEGORIES in the Brown Corpus : \", len(brown.categories()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c3dee",
   "metadata": {},
   "source": [
    "**Words & Sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a70525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
      "\n",
      " No. of Words/Tokens in the Brown Corpus :  1161192\n",
      "\n",
      " [['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
      "\n",
      " No. of Sentences in the Brown Corpus :  57340\n"
     ]
    }
   ],
   "source": [
    "print(brown.words())\n",
    "print(\"\\n No. of Words/Tokens in the Brown Corpus : \", len(brown.words()))\n",
    "print(\"\\n\", brown.sents())\n",
    "print(\"\\n No. of Sentences in the Brown Corpus : \", len(brown.sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503d814",
   "metadata": {},
   "source": [
    "**Unique Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6eea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens in Brown Corpus: 56057\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = len(set(brown.words()))\n",
    "print(\"Number of unique tokens in Brown Corpus:\", unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc04a1",
   "metadata": {},
   "source": [
    "**Sizeof()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8944f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Brown Corpus: 24 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the Brown Corpus:\", brown.__sizeof__(), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8db21",
   "metadata": {},
   "source": [
    "**<u>Find the size of word tokens?</u>**\n",
    "\n",
    "==> total no. of word tokens in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff8a30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word tokens in Brown Corpus: 1161192\n"
     ]
    }
   ],
   "source": [
    "word_tokens = len(brown.words())\n",
    "print(\"Size of word tokens in Brown Corpus:\", word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ff1d2",
   "metadata": {},
   "source": [
    "**<u>Find the size of word types?</u>**\n",
    "\n",
    "==> the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e87afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word types in Brown Corpus: 56057\n"
     ]
    }
   ],
   "source": [
    "word_types = len(set(brown.words()))\n",
    "print(\"Size of word types in Brown Corpus:\", word_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a152b9",
   "metadata": {},
   "source": [
    "**<u>Find the size of the category “government”</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16e1eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'government' category in Brown Corpus: 70117 words \n"
     ]
    }
   ],
   "source": [
    "government_words = brown.words(categories='government')\n",
    "government_word_count = len(government_words)\n",
    "print(\"Size of 'government' category in Brown Corpus:\", government_word_count, \"words \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3dc84c",
   "metadata": {},
   "source": [
    "**<u>List the most frequent tokens</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f5ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent tokens in Brown Corpus: [('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011)]\n"
     ]
    }
   ],
   "source": [
    "freq_dist = nltk.FreqDist(brown.words())\n",
    "most_common_tokens = freq_dist.most_common(10)\n",
    "print(\"10 most frequent tokens in Brown Corpus:\", most_common_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2710f3",
   "metadata": {},
   "source": [
    "**<u>Count the number of sentences</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f219ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in Brown Corpus: 57340\n"
     ]
    }
   ],
   "source": [
    "sentences = brown.sents()\n",
    "num_sentences = len(sentences)\n",
    "print(\"Number of sentences in Brown Corpus:\", num_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04b089",
   "metadata": {},
   "source": [
    "**<u>SUMMARY :-</u>**\n",
    "\n",
    "* brown.categories() fn. => gives list of ALL categories\n",
    "* brown.words()  => gives a 1-D list of ALL words in the Brown Corpus\n",
    "* brown.sents()  => gives a 2-D list of ALL sentences in the Brown Corpus \n",
    "* Set =>  unordered collection data type that is iterable, mutable, and has no duplicate elements  ; represented by { } \n",
    "* len(set(brown.words()) => Gives the no. of word types in the corpus (no. of unique tokens)\n",
    "* brown.__sizeof__()  ==> return the size of an object(here, brown) in bytes. \n",
    "* freq_dist = nltk.FreqDist(brown.words())  =>  Gives the frequency of each token in the corpus.\n",
    "    frequency distribution object is created using the nltk.FreqDist() method, which is applied to the brown.words()\n",
    "* freq_dist.most_common(10)  => retrieve the most common words in a frequency distribution object created by the nltk.FreqDist() method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
