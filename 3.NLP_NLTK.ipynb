{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a659712d",
   "metadata": {},
   "source": [
    "**Create a text corpus with a minimum of 200 words (unique content). Implement the \n",
    "following text processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc84dc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world is a vast and complex place, full of wonders and mysteries. From the depths of the ocean to the far reaches of space, there is always something new to discover and explore.\n",
      "\n",
      "At the same time, the world can also be a dark and dangerous place. War, disease, poverty, and oppression are all too common, and can make life difficult for many people.\n",
      "\n",
      "Despite these challenges, humans have shown incredible resilience and creativity over the centuries. We have invented amazing technologies, created stunning works of art, and built great civilizations. We have explored new lands, and reached for the stars.\n",
      "\n",
      "Yet there is still much work to be done. Many people around the world are still struggling, and the planet itself is facing grave threats from climate change, pollution, and overconsumption.\n",
      "\n",
      "As we look to the future, it is up to all of us to work together to build a better world. We must use our knowledge and resources to solve the problems that face us, and create a more just, sustainable, and peaceful world for all people.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "corpus = \"\"\"The world is a vast and complex place, full of wonders and mysteries. From the depths of the ocean to the far reaches of space, there is always something new to discover and explore.\n",
    "\n",
    "At the same time, the world can also be a dark and dangerous place. War, disease, poverty, and oppression are all too common, and can make life difficult for many people.\n",
    "\n",
    "Despite these challenges, humans have shown incredible resilience and creativity over the centuries. We have invented amazing technologies, created stunning works of art, and built great civilizations. We have explored new lands, and reached for the stars.\n",
    "\n",
    "Yet there is still much work to be done. Many people around the world are still struggling, and the planet itself is facing grave threats from climate change, pollution, and overconsumption.\n",
    "\n",
    "As we look to the future, it is up to all of us to work together to build a better world. We must use our knowledge and resources to solve the problems that face us, and create a more just, sustainable, and peaceful world for all people.\"\"\"\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79bfd4",
   "metadata": {},
   "source": [
    "**<u>WORD SEGMENTATION</u>**\n",
    "\n",
    "Word segmentation is the process of dividing a written text into individual words or tokens. Word segmentation is the process of dividing a written text into individual words or tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e8df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'world', 'is', 'a', 'vast', 'and', 'complex', 'place', ',', 'full', 'of', 'wonders', 'and', 'mysteries', '.', 'From', 'the', 'depths', 'of', 'the', 'ocean', 'to', 'the', 'far', 'reaches', 'of', 'space', ',', 'there', 'is', 'always', 'something', 'new', 'to', 'discover', 'and', 'explore', '.', 'At', 'the', 'same', 'time', ',', 'the', 'world', 'can', 'also', 'be', 'a', 'dark', 'and', 'dangerous', 'place', '.', 'War', ',', 'disease', ',', 'poverty', ',', 'and', 'oppression', 'are', 'all', 'too', 'common', ',', 'and', 'can', 'make', 'life', 'difficult', 'for', 'many', 'people', '.', 'Despite', 'these', 'challenges', ',', 'humans', 'have', 'shown', 'incredible', 'resilience', 'and', 'creativity', 'over', 'the', 'centuries', '.', 'We', 'have', 'invented', 'amazing', 'technologies', ',', 'created', 'stunning', 'works', 'of', 'art', ',', 'and', 'built', 'great', 'civilizations', '.', 'We', 'have', 'explored', 'new', 'lands', ',', 'and', 'reached', 'for', 'the', 'stars', '.', 'Yet', 'there', 'is', 'still', 'much', 'work', 'to', 'be', 'done', '.', 'Many', 'people', 'around', 'the', 'world', 'are', 'still', 'struggling', ',', 'and', 'the', 'planet', 'itself', 'is', 'facing', 'grave', 'threats', 'from', 'climate', 'change', ',', 'pollution', ',', 'and', 'overconsumption', '.', 'As', 'we', 'look', 'to', 'the', 'future', ',', 'it', 'is', 'up', 'to', 'all', 'of', 'us', 'to', 'work', 'together', 'to', 'build', 'a', 'better', 'world', '.', 'We', 'must', 'use', 'our', 'knowledge', 'and', 'resources', 'to', 'solve', 'the', 'problems', 'that', 'face', 'us', ',', 'and', 'create', 'a', 'more', 'just', ',', 'sustainable', ',', 'and', 'peaceful', 'world', 'for', 'all', 'people', '.']\n",
      "\n",
      " No. of Words/Tokens in the Corpus :  209\n",
      "\n",
      " Number of Unique tokens in Corpus: 118\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(corpus)\n",
    "print(words)\n",
    "\n",
    "print(\"\\n No. of Words/Tokens in the Corpus : \", len(words))\n",
    "print(\"\\n Number of Unique tokens in Corpus:\", len(set(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf8fbd",
   "metadata": {},
   "source": [
    "**<u>SENTENCE SEGMENTATION</u>**\n",
    "\n",
    "Sentence segmentation is the process of dividing a text into individual sentences. This is a fundamental task in natural language processing, as many algorithms and models operate at the level of individual sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0ced1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The world is a vast and complex place, full of wonders and mysteries.', 'From the depths of the ocean to the far reaches of space, there is always something new to discover and explore.', 'At the same time, the world can also be a dark and dangerous place.', 'War, disease, poverty, and oppression are all too common, and can make life difficult for many people.', 'Despite these challenges, humans have shown incredible resilience and creativity over the centuries.', 'We have invented amazing technologies, created stunning works of art, and built great civilizations.', 'We have explored new lands, and reached for the stars.', 'Yet there is still much work to be done.', 'Many people around the world are still struggling, and the planet itself is facing grave threats from climate change, pollution, and overconsumption.', 'As we look to the future, it is up to all of us to work together to build a better world.', 'We must use our knowledge and resources to solve the problems that face us, and create a more just, sustainable, and peaceful world for all people.']\n",
      "\n",
      " No. of Sentences in the Corpus :  11\n"
     ]
    }
   ],
   "source": [
    "sents = nltk.sent_tokenize(corpus)\n",
    "print(sents)\n",
    "\n",
    "print(\"\\n No. of Sentences in the Corpus : \", len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f525cec",
   "metadata": {},
   "source": [
    "**<u>CONVERT TO LOWERCASE</u>**\n",
    "\n",
    "Converting text to lowercase is a common preprocessing step in natural language processing, as it can help reduce the dimensionality of the data and improve the accuracy of certain models. It is also useful for normalization, as it can help ensure that words are treated as equivalent regardless of their case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75c7cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world is a vast and complex place, full of wonders and mysteries. from the depths of the ocean to the far reaches of space, there is always something new to discover and explore.\n",
      "\n",
      "at the same time, the world can also be a dark and dangerous place. war, disease, poverty, and oppression are all too common, and can make life difficult for many people.\n",
      "\n",
      "despite these challenges, humans have shown incredible resilience and creativity over the centuries. we have invented amazing technologies, created stunning works of art, and built great civilizations. we have explored new lands, and reached for the stars.\n",
      "\n",
      "yet there is still much work to be done. many people around the world are still struggling, and the planet itself is facing grave threats from climate change, pollution, and overconsumption.\n",
      "\n",
      "as we look to the future, it is up to all of us to work together to build a better world. we must use our knowledge and resources to solve the problems that face us, and create a more just, sustainable, and peaceful world for all people.\n"
     ]
    }
   ],
   "source": [
    "lowercase_text = corpus.lower()\n",
    "print(lowercase_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bcb517",
   "metadata": {},
   "source": [
    "**<u>STOPWORDS REMOVAL</u>**\n",
    "\n",
    "Stop words are commonly used words that are generally considered to be of little value in natural language processing, as they do not carry much meaning and can add noise to the data. Examples of stop words in English include \"the\", \"and\", \"of\", \"to\", and \"in\".\n",
    "\n",
    "Removing stop words is a common preprocessing step in natural language processing, as it can help reduce the dimensionality of the data and improve the accuracy of certain models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9455c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world vast complex place , full wonders mysteries . depths ocean far reaches space , always something new discover explore . time , world also dark dangerous place . War , disease , poverty , oppression common , make life difficult many people . Despite challenges , humans shown incredible resilience creativity centuries . invented amazing technologies , created stunning works art , built great civilizations . explored new lands , reached stars . Yet still much work done . Many people around world still struggling , planet facing grave threats climate change , pollution , overconsumption . look future , us work together build better world . must use knowledge resources solve problems face us , create , sustainable , peaceful world people .\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "filtered_words = []\n",
    "for wrd in words:\n",
    "    if wrd.lower() not in stopwords.words('english'):\n",
    "        filtered_words.append(wrd)\n",
    "\n",
    "filtered_text = ' '.join(filtered_words)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0afd74",
   "metadata": {},
   "source": [
    "**<u>STEMMING</u>**\n",
    "\n",
    "Stemming is the process of reducing inflected or derived words to their base or root form. Stemming is a common preprocessing step in natural language processing, as it can help reduce the dimensionality of the data and improve the accuracy of certain models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e1cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world >>> world\n",
      "vast >>> vast\n",
      "complex >>> complex\n",
      "place >>> place\n",
      ", >>> ,\n",
      "full >>> full\n",
      "wonders >>> wonder\n",
      "mysteries >>> mysteri\n",
      ". >>> .\n",
      "depths >>> depth\n",
      "ocean >>> ocean\n",
      "far >>> far\n",
      "reaches >>> reach\n",
      "space >>> space\n",
      ", >>> ,\n",
      "always >>> alway\n",
      "something >>> someth\n",
      "new >>> new\n",
      "discover >>> discov\n",
      "explore >>> explor\n",
      ". >>> .\n",
      "time >>> time\n",
      ", >>> ,\n",
      "world >>> world\n",
      "also >>> also\n",
      "dark >>> dark\n",
      "dangerous >>> danger\n",
      "place >>> place\n",
      ". >>> .\n",
      "War >>> war\n",
      ", >>> ,\n",
      "disease >>> diseas\n",
      ", >>> ,\n",
      "poverty >>> poverti\n",
      ", >>> ,\n",
      "oppression >>> oppress\n",
      "common >>> common\n",
      ", >>> ,\n",
      "make >>> make\n",
      "life >>> life\n",
      "difficult >>> difficult\n",
      "many >>> mani\n",
      "people >>> peopl\n",
      ". >>> .\n",
      "Despite >>> despit\n",
      "challenges >>> challeng\n",
      ", >>> ,\n",
      "humans >>> human\n",
      "shown >>> shown\n",
      "incredible >>> incred\n",
      "resilience >>> resili\n",
      "creativity >>> creativ\n",
      "centuries >>> centuri\n",
      ". >>> .\n",
      "invented >>> invent\n",
      "amazing >>> amaz\n",
      "technologies >>> technolog\n",
      ", >>> ,\n",
      "created >>> creat\n",
      "stunning >>> stun\n",
      "works >>> work\n",
      "art >>> art\n",
      ", >>> ,\n",
      "built >>> built\n",
      "great >>> great\n",
      "civilizations >>> civil\n",
      ". >>> .\n",
      "explored >>> explor\n",
      "new >>> new\n",
      "lands >>> land\n",
      ", >>> ,\n",
      "reached >>> reach\n",
      "stars >>> star\n",
      ". >>> .\n",
      "Yet >>> yet\n",
      "still >>> still\n",
      "much >>> much\n",
      "work >>> work\n",
      "done >>> done\n",
      ". >>> .\n",
      "Many >>> mani\n",
      "people >>> peopl\n",
      "around >>> around\n",
      "world >>> world\n",
      "still >>> still\n",
      "struggling >>> struggl\n",
      ", >>> ,\n",
      "planet >>> planet\n",
      "facing >>> face\n",
      "grave >>> grave\n",
      "threats >>> threat\n",
      "climate >>> climat\n",
      "change >>> chang\n",
      ", >>> ,\n",
      "pollution >>> pollut\n",
      ", >>> ,\n",
      "overconsumption >>> overconsumpt\n",
      ". >>> .\n",
      "look >>> look\n",
      "future >>> futur\n",
      ", >>> ,\n",
      "us >>> us\n",
      "work >>> work\n",
      "together >>> togeth\n",
      "build >>> build\n",
      "better >>> better\n",
      "world >>> world\n",
      ". >>> .\n",
      "must >>> must\n",
      "use >>> use\n",
      "knowledge >>> knowledg\n",
      "resources >>> resourc\n",
      "solve >>> solv\n",
      "problems >>> problem\n",
      "face >>> face\n",
      "us >>> us\n",
      ", >>> ,\n",
      "create >>> creat\n",
      ", >>> ,\n",
      "sustainable >>> sustain\n",
      ", >>> ,\n",
      "peaceful >>> peac\n",
      "world >>> world\n",
      "people >>> peopl\n",
      ". >>> .\n",
      "\n",
      " world vast complex place , full wonder mysteri . depth ocean far reach space , alway someth new discov explor . time , world also dark danger place . war , diseas , poverti , oppress common , make life difficult mani peopl . despit challeng , human shown incred resili creativ centuri . invent amaz technolog , creat stun work art , built great civil . explor new land , reach star . yet still much work done . mani peopl around world still struggl , planet face grave threat climat chang , pollut , overconsumpt . look futur , us work togeth build better world . must use knowledg resourc solv problem face us , creat , sustain , peac world peopl .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = []\n",
    "\n",
    "for wrd in filtered_words:\n",
    "    stemmed_words.append(stemmer.stem(wrd))\n",
    "    print(wrd , \">>>\" , stemmer.stem(wrd))\n",
    "    \n",
    "stemmed_text = ' '.join(stemmed_words)\n",
    "print(\"\\n\", stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7392c2b",
   "metadata": {},
   "source": [
    "**<u>LEMMATIZATION</u>**\n",
    "\n",
    "Lemmatization is the process of reducing words to their base or dictionary form, or lemma. Unlike stemming, which simply removes the suffix of a word, lemmatization takes into account the part of speech and context of the word to determine the correct base form. For example, the lemma of \"running\", \"runs\", and \"ran\" is \"run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1724866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world >>> world\n",
      "vast >>> vast\n",
      "complex >>> complex\n",
      "place >>> place\n",
      ", >>> ,\n",
      "full >>> full\n",
      "wonders >>> wonder\n",
      "mysteries >>> mystery\n",
      ". >>> .\n",
      "depths >>> depth\n",
      "ocean >>> ocean\n",
      "far >>> far\n",
      "reaches >>> reach\n",
      "space >>> space\n",
      ", >>> ,\n",
      "always >>> always\n",
      "something >>> something\n",
      "new >>> new\n",
      "discover >>> discover\n",
      "explore >>> explore\n",
      ". >>> .\n",
      "time >>> time\n",
      ", >>> ,\n",
      "world >>> world\n",
      "also >>> also\n",
      "dark >>> dark\n",
      "dangerous >>> dangerous\n",
      "place >>> place\n",
      ". >>> .\n",
      "War >>> War\n",
      ", >>> ,\n",
      "disease >>> disease\n",
      ", >>> ,\n",
      "poverty >>> poverty\n",
      ", >>> ,\n",
      "oppression >>> oppression\n",
      "common >>> common\n",
      ", >>> ,\n",
      "make >>> make\n",
      "life >>> life\n",
      "difficult >>> difficult\n",
      "many >>> many\n",
      "people >>> people\n",
      ". >>> .\n",
      "Despite >>> Despite\n",
      "challenges >>> challenge\n",
      ", >>> ,\n",
      "humans >>> human\n",
      "shown >>> shown\n",
      "incredible >>> incredible\n",
      "resilience >>> resilience\n",
      "creativity >>> creativity\n",
      "centuries >>> century\n",
      ". >>> .\n",
      "invented >>> invented\n",
      "amazing >>> amazing\n",
      "technologies >>> technology\n",
      ", >>> ,\n",
      "created >>> created\n",
      "stunning >>> stunning\n",
      "works >>> work\n",
      "art >>> art\n",
      ", >>> ,\n",
      "built >>> built\n",
      "great >>> great\n",
      "civilizations >>> civilization\n",
      ". >>> .\n",
      "explored >>> explored\n",
      "new >>> new\n",
      "lands >>> land\n",
      ", >>> ,\n",
      "reached >>> reached\n",
      "stars >>> star\n",
      ". >>> .\n",
      "Yet >>> Yet\n",
      "still >>> still\n",
      "much >>> much\n",
      "work >>> work\n",
      "done >>> done\n",
      ". >>> .\n",
      "Many >>> Many\n",
      "people >>> people\n",
      "around >>> around\n",
      "world >>> world\n",
      "still >>> still\n",
      "struggling >>> struggling\n",
      ", >>> ,\n",
      "planet >>> planet\n",
      "facing >>> facing\n",
      "grave >>> grave\n",
      "threats >>> threat\n",
      "climate >>> climate\n",
      "change >>> change\n",
      ", >>> ,\n",
      "pollution >>> pollution\n",
      ", >>> ,\n",
      "overconsumption >>> overconsumption\n",
      ". >>> .\n",
      "look >>> look\n",
      "future >>> future\n",
      ", >>> ,\n",
      "us >>> u\n",
      "work >>> work\n",
      "together >>> together\n",
      "build >>> build\n",
      "better >>> better\n",
      "world >>> world\n",
      ". >>> .\n",
      "must >>> must\n",
      "use >>> use\n",
      "knowledge >>> knowledge\n",
      "resources >>> resource\n",
      "solve >>> solve\n",
      "problems >>> problem\n",
      "face >>> face\n",
      "us >>> u\n",
      ", >>> ,\n",
      "create >>> create\n",
      ", >>> ,\n",
      "sustainable >>> sustainable\n",
      ", >>> ,\n",
      "peaceful >>> peaceful\n",
      "world >>> world\n",
      "people >>> people\n",
      ". >>> .\n",
      "world vast complex place , full wonder mystery . depth ocean far reach space , always something new discover explore . time , world also dark dangerous place . War , disease , poverty , oppression common , make life difficult many people . Despite challenge , human shown incredible resilience creativity century . invented amazing technology , created stunning work art , built great civilization . explored new land , reached star . Yet still much work done . Many people around world still struggling , planet facing grave threat climate change , pollution , overconsumption . look future , u work together build better world . must use knowledge resource solve problem face u , create , sustainable , peaceful world people .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = []\n",
    "\n",
    "for wrd in filtered_words:\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(wrd))\n",
    "    print(wrd , \">>>\" , lemmatizer.lemmatize(wrd))\n",
    "\n",
    "lemmatized_text = ' '.join(lemmatized_words)\n",
    "print(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9626b69b",
   "metadata": {},
   "source": [
    "**<u>PART OF SPEECH TAGGER</u>**\n",
    "\n",
    "Part-of-speech (POS) tagging is the process of labeling each word in a sentence with its corresponding part of speech, such as noun, verb, adjective, etc. POS tagging is a fundamental task in natural language processing, as it can help disambiguate the meaning of words and improve the accuracy of certain models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b173eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('world', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('vast', 'JJ'), ('and', 'CC'), ('complex', 'JJ'), ('place', 'NN'), (',', ','), ('full', 'JJ'), ('of', 'IN'), ('wonders', 'NNS'), ('and', 'CC'), ('mysteries', 'NNS'), ('.', '.'), ('From', 'IN'), ('the', 'DT'), ('depths', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('ocean', 'NN'), ('to', 'TO'), ('the', 'DT'), ('far', 'RB'), ('reaches', 'VBZ'), ('of', 'IN'), ('space', 'NN'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('always', 'RB'), ('something', 'NN'), ('new', 'JJ'), ('to', 'TO'), ('discover', 'VB'), ('and', 'CC'), ('explore', 'VB'), ('.', '.'), ('At', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('time', 'NN'), (',', ','), ('the', 'DT'), ('world', 'NN'), ('can', 'MD'), ('also', 'RB'), ('be', 'VB'), ('a', 'DT'), ('dark', 'NN'), ('and', 'CC'), ('dangerous', 'JJ'), ('place', 'NN'), ('.', '.'), ('War', 'NNP'), (',', ','), ('disease', 'NN'), (',', ','), ('poverty', 'NN'), (',', ','), ('and', 'CC'), ('oppression', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('too', 'RB'), ('common', 'JJ'), (',', ','), ('and', 'CC'), ('can', 'MD'), ('make', 'VB'), ('life', 'NN'), ('difficult', 'JJ'), ('for', 'IN'), ('many', 'JJ'), ('people', 'NNS'), ('.', '.'), ('Despite', 'IN'), ('these', 'DT'), ('challenges', 'NNS'), (',', ','), ('humans', 'NNS'), ('have', 'VBP'), ('shown', 'VBN'), ('incredible', 'JJ'), ('resilience', 'NN'), ('and', 'CC'), ('creativity', 'NN'), ('over', 'IN'), ('the', 'DT'), ('centuries', 'NNS'), ('.', '.'), ('We', 'PRP'), ('have', 'VBP'), ('invented', 'VBN'), ('amazing', 'JJ'), ('technologies', 'NNS'), (',', ','), ('created', 'VBD'), ('stunning', 'VBG'), ('works', 'NNS'), ('of', 'IN'), ('art', 'NN'), (',', ','), ('and', 'CC'), ('built', 'VBD'), ('great', 'JJ'), ('civilizations', 'NNS'), ('.', '.'), ('We', 'PRP'), ('have', 'VBP'), ('explored', 'VBN'), ('new', 'JJ'), ('lands', 'NNS'), (',', ','), ('and', 'CC'), ('reached', 'VBD'), ('for', 'IN'), ('the', 'DT'), ('stars', 'NNS'), ('.', '.'), ('Yet', 'CC'), ('there', 'EX'), ('is', 'VBZ'), ('still', 'RB'), ('much', 'JJ'), ('work', 'NN'), ('to', 'TO'), ('be', 'VB'), ('done', 'VBN'), ('.', '.'), ('Many', 'JJ'), ('people', 'NNS'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('are', 'VBP'), ('still', 'RB'), ('struggling', 'VBG'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('planet', 'NN'), ('itself', 'PRP'), ('is', 'VBZ'), ('facing', 'VBG'), ('grave', 'JJ'), ('threats', 'NNS'), ('from', 'IN'), ('climate', 'NN'), ('change', 'NN'), (',', ','), ('pollution', 'NN'), (',', ','), ('and', 'CC'), ('overconsumption', 'NN'), ('.', '.'), ('As', 'IN'), ('we', 'PRP'), ('look', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('future', 'NN'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('up', 'IN'), ('to', 'TO'), ('all', 'DT'), ('of', 'IN'), ('us', 'PRP'), ('to', 'TO'), ('work', 'VB'), ('together', 'RB'), ('to', 'TO'), ('build', 'VB'), ('a', 'DT'), ('better', 'JJR'), ('world', 'NN'), ('.', '.'), ('We', 'PRP'), ('must', 'MD'), ('use', 'VB'), ('our', 'PRP$'), ('knowledge', 'NN'), ('and', 'CC'), ('resources', 'NNS'), ('to', 'TO'), ('solve', 'VB'), ('the', 'DT'), ('problems', 'NNS'), ('that', 'WDT'), ('face', 'VBP'), ('us', 'PRP'), (',', ','), ('and', 'CC'), ('create', 'VB'), ('a', 'DT'), ('more', 'RBR'), ('just', 'RB'), (',', ','), ('sustainable', 'JJ'), (',', ','), ('and', 'CC'), ('peaceful', 'JJ'), ('world', 'NN'), ('for', 'IN'), ('all', 'DT'), ('people', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(corpus)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "print(pos_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
