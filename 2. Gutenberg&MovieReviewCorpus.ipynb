{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecad71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f32a9",
   "metadata": {},
   "source": [
    "  **Gutenberg Corpus:** A collection of literary works in English, with over 25,000 texts from Project Gutenberg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897ef62",
   "metadata": {},
   "source": [
    "**Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e261773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS of Gutenberg Corpus : \n",
      "  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]\n",
      "\n",
      " No. of Words/Tokens in the Gutenberg Corpus :  2621613\n"
     ]
    }
   ],
   "source": [
    "print(\"WORDS of Gutenberg Corpus : \\n \", gutenberg.words())\n",
    "print(\"\\n No. of Words/Tokens in the Gutenberg Corpus : \", len(gutenberg.words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96320e6d",
   "metadata": {},
   "source": [
    "**Unique Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0385430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens in Brown Corpus: 51156\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = len(set(gutenberg.words()))\n",
    "print(\"Number of unique tokens in Brown Corpus:\", unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da343c98",
   "metadata": {},
   "source": [
    "**Sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d906c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences of Gutenberg Corpus : \n",
      "  [['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ...]\n",
      "\n",
      " No. of Sentences in the Gutenberg Corpus :  98552\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences of Gutenberg Corpus : \\n \", gutenberg.sents())\n",
    "print(\"\\n No. of Sentences in the Gutenberg Corpus : \", len(gutenberg.sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aef20f",
   "metadata": {},
   "source": [
    "  **Movie Reviews Corpus:** A collection of movie reviews with pre-assigned sentiment labels (positive or negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6326668",
   "metadata": {},
   "source": [
    "**Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25348e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS of Movie_Reviews Corpus : \n",
      "  ['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
      "\n",
      " No. of Words/Tokens in the Movie_Reviews Corpus :  1583820\n"
     ]
    }
   ],
   "source": [
    "print(\"WORDS of Movie_Reviews Corpus : \\n \", movie_reviews.words())\n",
    "print(\"\\n No. of Words/Tokens in the Movie_Reviews Corpus : \", len(movie_reviews.words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692fc2b",
   "metadata": {},
   "source": [
    "**Unique Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7eb2a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of Unique tokens in Movie_Reviews Corpus: 39768\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = len(set(movie_reviews.words()))\n",
    "print(\"\\n Number of Unique tokens in Movie_Reviews Corpus:\", unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3ebd9",
   "metadata": {},
   "source": [
    "**Sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "368f8438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences of Movie_Reviews Corpus : \n",
      "  [['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]\n",
      "\n",
      " No. of Sentences in the Movie_Reviews Corpus :  71532\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences of Movie_Reviews Corpus : \\n \", movie_reviews.sents())\n",
    "print(\"\\n No. of Sentences in the Movie_Reviews Corpus : \", len(movie_reviews.sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2ef27",
   "metadata": {},
   "source": [
    "**<u>POS TAGGING</u>**\n",
    "\n",
    "POS tagging is the task of labeling each word in a sentence with its part of speech, such as noun, verb, adjective, or adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72e9175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10th Sentence in the Gutenberg Corpus : \n",
      " The danger , however , was at present so unperceived , that they did not by any means rank as misfortunes with her .\n",
      "\n",
      " POS Tagged : \n",
      " [('The', 'DT'), ('danger', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('was', 'VBD'), ('at', 'IN'), ('present', 'JJ'), ('so', 'RB'), ('unperceived', 'JJ'), (',', ','), ('that', 'IN'), ('they', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('by', 'IN'), ('any', 'DT'), ('means', 'NNS'), ('rank', 'NN'), ('as', 'IN'), ('misfortunes', 'NNS'), ('with', 'IN'), ('her', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "Gutenberg_sentences = gutenberg.sents()\n",
    "print(\"The 10th Sentence in the Gutenberg Corpus : \\n\", ' '.join(Gutenberg_sentences[10]))\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "tagged_sentence = nltk.pos_tag(Gutenberg_sentences[10])\n",
    "print(\"\\n POS Tagged : \\n\", tagged_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d1ddc",
   "metadata": {},
   "source": [
    "**<u>PARSING</u>**\n",
    "\n",
    "Parsing is the process of analyzing a sentence or a text in order to determine its syntactic structure, and is an important task in natural language processing (NLP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dea77dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (DT the) (NN cat)) (VP (VBZ chases) (NP (DT the) (NN dog))))\n"
     ]
    }
   ],
   "source": [
    "# Define a grammar rule for a simple sentence\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> DT NN\n",
    "    VP -> VBZ NP | VBD NP\n",
    "    DT -> 'the'\n",
    "    NN -> 'cat' | 'dog'\n",
    "    VBZ -> 'chases'\n",
    "    VBD -> 'chased'\n",
    "\"\"\")\n",
    "\n",
    "# Create the parser\n",
    "parser = nltk.RecursiveDescentParser(grammar)\n",
    "\n",
    "# Parse a sentence\n",
    "sentence = \"the cat chases the dog\"\n",
    "for tree in parser.parse(nltk.word_tokenize(sentence)):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212083d9",
   "metadata": {},
   "source": [
    "**<u>SPOKEN LANGUAGE</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ab399",
   "metadata": {},
   "source": [
    "Tokenizing spoken language: NLTK provides a tokenizer that can split spoken language into words, known as the word_tokenize method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0df21460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['um', ',', 'I', 'do', \"n't\", 'know', ',', 'like', ',', 'this', 'is', ',', 'like', ',', 'really', 'cool', ',', 'you', 'know', '?']\n"
     ]
    }
   ],
   "source": [
    "spoken_text = \"um, I don't know, like, this is, like, really cool, you know?\"\n",
    "\n",
    "# Tokenize the spoken language\n",
    "tokens = nltk.word_tokenize(spoken_text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6930ad",
   "metadata": {},
   "source": [
    "**Removing filler words:** Spoken language often includes filler words, such as \"um\" or \"like\". You can use NLTK to remove these filler words using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f419dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", I don't know, , this is, , really cool, you know?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regular expression pattern to match filler words\n",
    "filler_pattern = re.compile(r'\\b(um|uh|like)\\b')\n",
    "\n",
    "# Remove filler words from the spoken language\n",
    "spoken_text_without_fillers = re.sub(filler_pattern, '', spoken_text)\n",
    "\n",
    "print(spoken_text_without_fillers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ce98d",
   "metadata": {},
   "source": [
    "**Analyzing sentiment in spoken language:** NLTK provides a sentiment analysis module that can be used to classify the sentiment of spoken language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36ee55f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.568, 'pos': 0.432, 'compound': 0.765}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "spoken_text = \"I'm feeling pretty good about the presentation, although I did stumble over a few words.\"\n",
    "\n",
    "# Create a sentiment analyzer object\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze the sentiment of the spoken language\n",
    "sentiment_scores = sentiment_analyzer.polarity_scores(spoken_text)\n",
    "\n",
    "print(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b21c020",
   "metadata": {},
   "source": [
    "**<u>SEMANTIC TAGGED</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2406852",
   "metadata": {},
   "source": [
    "Semantic tagging (also known as part-of-speech tagging) is the process of assigning a part of speech to each word in a text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5681f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('and', 'CC'), ('bought', 'VBD'), ('some', 'DT'), ('milk', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Load the default NLTK tagger\n",
    "tagger = nltk.pos_tag\n",
    "\n",
    "# Tokenize the text\n",
    "text = \"I went to the store and bought some milk.\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Perform semantic tagging on the tokens\n",
    "tagged_tokens = tagger(tokens)\n",
    "\n",
    "# Print the tagged tokens\n",
    "print(tagged_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
